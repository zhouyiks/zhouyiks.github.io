<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Multimodal Large Language Models, Image Tokenizer">
    <meta name="description" content="SAMTok provides a unified mask-token interface for MLLMs.">

    <title>SAMTok: Representing Any Mask with Two Words</title>

    <!-- Â≠ó‰Ωì‰∏éÂõæÊ†á -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fontsource/nunito@5.0.18/index.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@1.0.1/css/bulma.min.css">
    <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.2/css/fontawesome.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css">

    <!-- Bootstrap 5 -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Zoom Êèí‰ª∂ -->
    <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"></script>

    <!-- MathJax -->
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                packages: { '[+]': ['ams'] }
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <style>
        body {
            font-family: 'Nunito', sans-serif;
            background-color: #f8f9fa;
            /* ÊûÅÊµÖÁöÑÁÅ∞Ëâ≤ËÉåÊôØÔºåÊä§Áúº */
            color: #2c3e50;
        }

        /* ------------------- Hero Section ------------------- */
        .hero {
            background-color: #fff;
            padding-bottom: 3rem;
        }

        .hero .logo {
            max-width: 400px;
            /* ÈôêÂà∂LogoÂÆΩÂ∫¶ */
            width: 80%;
            height: auto;
            margin-bottom: 1.5rem;
        }

        .publication-title {
            font-size: 2.5rem;
            font-weight: 800;
            color: #000;
            /* Á∫ØÈªëÊ†áÈ¢òÔºåÈ´òÂØπÊØîÂ∫¶ */
            line-height: 1.2;
            margin-bottom: 1.5rem !important;
        }

        .author-block a {
            color: #3273dc;
            text-decoration: none;
            font-weight: 600;
        }

        .author-block a:hover {
            text-decoration: underline;
        }

        .publication-links .button {
            border-radius: 20px;
            font-weight: 600;
            transition: all 0.2s;
        }

        .publication-links .button:hover {
            transform: scale(1.05);
        }

        /* ------------------- Section Headings ------------------- */
        .section-title {
            font-weight: 800;
            font-size: 2rem;
            margin-bottom: 2rem;
            color: #1a1a1a;
            text-align: center;
        }

        /* ------------------- Motivation Cards (Modified) ------------------- */
        .feature-card {
            /* ‰øÆÊîπËÉåÊôØËâ≤Ôºå‰∏çÂÜç‰ΩøÁî®ÁôΩËâ≤ÔºåÊîπ‰∏∫Ê∑°ËìùËâ≤‰ª•Á™ÅÂá∫ÊòæÁ§∫ */
            background: #e7f1ff;
            border-radius: 12px;
            padding: 2rem 1.5rem;
            height: 100%;
            /* Â¢ûÂä†ËæπÊ°ÜÈ¢úËâ≤ÔºåÂ¢ûÂº∫ËßÜËßâÂå∫ÂàÜ */
            border: 2px solid #3273dc;
            box-shadow: 0 4px 15px rgba(50, 115, 220, 0.15);
            transition: transform 0.2s, box-shadow 0.2s;
        }

        .feature-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 25px rgba(50, 115, 220, 0.25);
            background: #dbeaff;
            /* hoverÊó∂Á®çÂæÆÂä†Ê∑± */
        }

        .feature-icon {
            font-size: 2.5rem;
            margin-bottom: 1rem;
            color: #3273dc;
        }

        .feature-title {
            font-weight: 800;
            font-size: 1.25rem;
            margin-bottom: 0.75rem;
            color: #0d2847;
            /* Êõ¥Ê∑±ÁöÑËìùËâ≤Ê†áÈ¢ò */
        }

        .feature-text {
            color: #2c3e50;
            font-size: 1rem;
            line-height: 1.5;
            font-weight: 500;
        }

        /* ------------------- Figures & Captions ------------------- */
        .figure-container {
            margin-bottom: 3rem;
            text-align: center;
        }

        .figure-img {
            border-radius: 8px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.08);
            margin-bottom: 1rem;
            width: 100%;
        }

        /* ÈíàÂØπ Figure 2 ÁöÑÁâπÊÆäÁº©Â∞èÂ§ÑÁêÜ - Modified to 45% */
        .figure-img-small {
            width: 45% !important;
            /* ‰ªé 60% ‰øÆÊîπ‰∏∫ 45% */
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
            display: block;
        }

        .caption-content {
            background-color: #fff;
            border-left: 4px solid #3273dc;
            padding: 1rem;
            text-align: justify;
            font-size: 1rem;
            color: #2c3e50;
            /* Ê∑±Ëâ≤ÊñáÂ≠ó */
            margin-top: 10px;
            border-radius: 0 4px 4px 0;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05);
        }

        figcaption {
            font-weight: 700;
            color: #000;
            margin-bottom: 0.5rem;
            display: block;
            text-align: center;
            font-size: 1.1rem;
        }

        /* ------------------- Results Grid ------------------- */
        .result-card {
            background: #fff;
            padding: 10px;
            border-radius: 8px;
            margin-bottom: 20px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
        }

        /* Header class is technically not needed anymore if we remove elements, 
           but kept for potential layout stability */
        .result-header {
            display: none;
            /* Hide via CSS just in case */
        }

        /* ------------------- Visualization Carousel (Modified) ------------------- */
        .viz-section {
            background-color: #343a40;
            padding-top: 3rem;
            padding-bottom: 3rem;
        }

        .viz-section .section-title {
            color: #fff;
        }

        /* ‰øÆÊîπÂÆπÂô®‰ª•ÈÄÇÂ∫îÂÖ®ÂÆΩÂõæÁâá */
        .carousel-item-container {
            background: #212529;
            padding: 20px 0;
            /* ÂáèÂ∞ëÂ∑¶Âè≥padding */
            border-radius: 10px 10px 0 0;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: auto;
            /* ÁßªÈô§ÊúÄÂ∞èÈ´òÂ∫¶ÈôêÂà∂ÔºåËÆ©ÂõæÁâáÊíëÂºÄ */
        }

        .carousel-item img {
            max-height: none;
            /* ÁßªÈô§È´òÂ∫¶ÈôêÂà∂ */
            width: 80%;
            /* ËÆæÁΩÆ‰∏∫È°µÈù¢ÂÆΩÂ∫¶ÁöÑ80%ÔºåÂÆûÁé∞Â∞ΩÂèØËÉΩÊîæÂ§ß */
            height: auto;
            /* ‰øùÊåÅÊØî‰æã */
            max-width: 100%;
            object-fit: contain;
            border-radius: 4px;
        }

        .carousel-caption-box {
            background: #ffffff;
            color: #000000;
            padding: 1.5rem 2rem;
            border-radius: 0 0 10px 10px;
            text-align: justify;
            font-size: 1rem;
            line-height: 1.6;
            /* ÈôêÂà∂ÊñáÂ≠óÁõíÂ≠êÁöÑÊúÄÂ§ßÂÆΩÂ∫¶Ôºå‰ΩøÂÖ∂‰∏éÂõæÁâáËßÜËßâÂçèË∞ÉÔºåÊàñËÄÖ‰øùÊåÅÂÖ®ÂÆΩ */
            width: 80%;
            margin: 0 auto;
            /* Â±Ö‰∏≠ */
        }

        .carousel-control-prev,
        .carousel-control-next {
            width: 8%;
            /* Âä†ÂÆΩÁÇπÂáªÂå∫Âüü */
        }
    </style>
</head>

<body>
    <!-- Hero Section -->
    <section class="hero">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full">
                    <img class="logo" src="assets/logo.png" alt="logo">
                    <h1 class="title publication-title">
                        SAMTok: Representing Any Mask with Two Words
                    </h1>

                    <!-- Authors -->
                    <div class="is-size-5 publication-author">
                        <span class="author-block"><a
                                href="https://scholar.google.com/citations?user=dZikW2YAAAAJ&hl=en&oi=ao"
                                target="_blank">Yikang Zhou</a><sup>1,2</sup>,</span>
                        <span class="author-block"><a
                                href="https://scholar.google.com/citations?hl=zh-CN&user=3xu4a5oAAAAJ"
                                target="_blank">Tao Zhang</a><sup>1</sup>,</span>
                        <span class="author-block">Dengxian Gong<sup>1</sup>,</span>
                        <span class="author-block">Yuanzheng Wu<sup>1</sup>,</span>
                        <span class="author-block">Haochen Wang<sup>2</sup>,</span>
                        <span class="author-block">Ye Tian<sup>2</sup>,</span>
                        <span class="author-block">Haobo Yuan<sup>1</sup>,</span>
                        <span class="author-block">Jiacong Wang<sup>2</sup>,</span>
                        <span class="author-block">Lu Qi<sup>1</sup>,</span>
                        <span class="author-block">Hao Fei<sup>3</sup>,</span>
                        <span class="author-block"><a
                                href="https://scholar.google.com/citations?hl=zh-CN&user=FjoRmF4AAAAJ"
                                target="_blank">Shunping Ji</a><sup>1,‚úâÔ∏è</sup>,</span>
                        <span class="author-block">Anran Wang<sup>2</sup>,</span>
                        <span class="author-block">Zhuochen Wang<sup>2</sup>,</span>
                        <span class="author-block">Yujing Wang<sup>2</sup>,</span>
                        <span class="author-block">Cheng CHEN<sup>2</sup>,</span>
                        <span class="author-block"><a href="https://lxtgh.github.io/" target="_blank">Xiangtai
                                Li</a><sup>2,‚úâÔ∏è</sup></span>
                    </div>

                    <div class="is-size-5 publication-institution mt-3">
                        <span class="author-block"><sup>1</sup>Wuhan University</span> &nbsp;&nbsp;
                        <span class="author-block"><sup>2</sup>ByteDance</span> &nbsp;&nbsp;
                        <span class="author-block"><sup>3</sup>National University of Singapore</span>
                    </div>

                    <div class="publication-links mt-5">
                        <span class="link-block">
                            <a href="https://arxiv.org/abs/2408.03326" class="external-link button is-dark is-rounded">
                                <span class="icon"><i class="ai ai-arxiv"></i></span>
                                <span>arXiv</span>
                            </a>
                        </span>
                        <span class="link-block">
                            <a href="https://github.com/bytedance/Sa2VA/tree/main/projects/samtok"
                                class="external-link button is-dark is-rounded">
                                <span class="icon"><i class="fab fa-github"></i></span>
                                <span>Training Code</span>
                            </a>
                        </span>
                        <span class="link-block">
                            <a href="https://huggingface.co/collections/zhouyik/samtok"
                                class="external-link button is-dark is-rounded">
                                <span class="icon">ü§ó</span>
                                <span>Checkpoints</span>
                            </a>
                        </span>
                        <span class="link-block">
                            <a href="https://huggingface.co/spaces/zhouyik/SAMTok"
                                class="external-link button is-dark is-rounded">
                                <span class="icon">üé®</span>
                                <span>Live Demo</span>
                            </a>
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- 2. Motivation ÈáçÊûÑÔºöFeature Grid -->
    <section class="section has-background-light">
        <div class="container is-max-desktop">
            <h2 class="section-title">Why SAMTok?</h2>
            <div class="columns is-multiline">
                <!-- Feature 1 -->
                <div class="column is-6">
                    <div class="feature-card has-text-centered">
                        <div class="feature-icon"><i class="fas fa-language"></i></div>
                        <h3 class="feature-title">Mask as Language</h3>
                        <p class="feature-text">
                            Unifies mask understanding and generation into a single linguistic framework. No need for
                            separate complex decoders or pooling layers.
                        </p>
                    </div>
                </div>
                <!-- Feature 2 -->
                <div class="column is-6">
                    <div class="feature-card has-text-centered">
                        <div class="feature-icon"><i class="fas fa-bolt"></i></div>
                        <h3 class="feature-title">Extreme Efficiency</h3>
                        <p class="feature-text">
                            Represents any complex mask with just <strong>two discrete tokens</strong>, significantly
                            reducing inference cost compared to polygon or RLE formats.
                        </p>
                    </div>
                </div>
                <!-- Feature 3 -->
                <div class="column is-6">
                    <div class="feature-card has-text-centered">
                        <div class="feature-icon"><i class="fas fa-robot"></i></div>
                        <h3 class="feature-title">RL-Ready</h3>
                        <p class="feature-text">
                            Since masks are discrete tokens, standard Reinforcement Learning (RL) can be directly
                            applied to optimize pixel-wise generation.
                        </p>
                    </div>
                </div>
                <!-- Feature 4 -->
                <div class="column is-6">
                    <div class="feature-card has-text-centered">
                        <div class="feature-icon"><i class="fas fa-puzzle-piece"></i></div>
                        <h3 class="feature-title">Plug-and-Play</h3>
                        <p class="feature-text">
                            Non-intrusive design allows any base MLLM (like QwenVL) to acquire pixel-wise capabilities
                            via simple next-token prediction training.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Workflow (Previously Contributions) & Architecture -->
    <section class="section has-background-white">
        <div class="container is-max-desktop">
            <!-- Ê†áÈ¢ò‰øÆÊîπÔºöContributions -> Workflow -->
            <h2 class="section-title">Workflow</h2>

            <!-- Figure 1 -->
            <div class="figure-container">
                <img src="figures/teaser.png" alt="Teaser" class="figure-img zoom-img" />
                <figcaption>Figure 1</figcaption>
                <div class="caption-content">
                    We propose SAMTok, a discrete mask tokenizer that can tokenize masks into textual special words and
                    detokenize the textual special words into masks, which can transform masks into a new language for
                    MLLMs to learn like regular text data. As shown in Figure 1, our proposed SAMTok can convert diverse
                    masks into textual special tokens and accurately reconstruct the corresponding masks. Through
                    SAMTok, any MLLM can acquire powerful pixel-wise capabilities by learning like language data through
                    supervised fine-tuning and reinforcement learning, without any additional architectural
                    modifications or specialized loss design.
                </div>
            </div>

            <hr style="margin: 3rem 0;">

            <h2 class="section-title">SAMTok Architecture</h2>

            <!-- Figure 2 -->
            <div class="figure-container">
                <!-- ÈáçÁÇπÔºöfigure-img-small Ê†∑ÂºèÂ∑≤Âú® CSS ‰∏≠Ë∞ÉÊï¥‰∏∫ 45% -->
                <img src="figures/tokenizer.png" alt="Tokenizer" class="figure-img figure-img-small zoom-img" />
                <figcaption>Figure 2</figcaption>
                <div class="caption-content">
                    SAMTok has an encoder \(f_{\text{enc}}\), a vector quantizer with codebook \(\mathcal{C}\), and a
                    decoder \(f_{\text{dec}}\). Both \(f_{\text{enc}}\) and \(f_{\text{dec}}\) are instantiated with a
                    SAM model, which includes an image backbone \(f_{\text{img}}\), a prompt encoder \(f_{\text{prm}}\),
                    and a mask decoder \(f_{\text{msk}}\). Given an input image \(\mathcal{I}\) and a region
                    \(\mathcal{M}\) (e.g., the area outlined in purple), the SAMTok encoder \(f_{\text{enc}}\) first
                    encodes the 2D mask into a mask embedding \(\mathbf{z}\), then performs two-stage quantization to
                    obtain discrete mask embeddings \([\mathbf{e}_1, \mathbf{e}_2]\). The SAMTok decoder
                    \(f_{\text{dec}}\) reconstructs the 2D mask \(\hat{\mathcal{M}}\) from the original image and the
                    region's discrete mask embeddings.
                </div>
            </div>

            <!-- Figure 3 -->
            <div class="figure-container">
                <img src="figures/vlm_samtok.png" alt="vlm_samtok" class="figure-img zoom-img" />
                <figcaption>Figure 3</figcaption>
                <div class="caption-content">
                    For the mask understanding task, SAMTok first tokenizes region masks into quantization codes, then
                    formats them into mask words, which are used in the MLLM prompt to refer to the corresponding image
                    regions. For the mask generation task, the MLLM first produces mask words according to the
                    instruction, then maps these mask words to quantization codes, after which SAMTok reconstructs the
                    2D masks.
                </div>
            </div>

        </div>
    </section>

    <!-- Main Results (Grid Layout - Text Headers Removed) -->
    <section class="section">
        <div class="container is-max-desktop">
            <h2 class="section-title">Main Results</h2>

            <!-- Removed text captions (result-header) as requested -->

            <div class="row">
                <div class="col-md-12 result-card">
                    <img src="figures/table1.png" class="w-100 zoom-img">
                </div>
            </div>

            <div class="row">
                <div class="col-md-6">
                    <div class="result-card">
                        <img src="figures/table2.png" class="w-100 zoom-img">
                    </div>
                </div>
                <div class="col-md-6">
                    <div class="result-card">
                        <img src="figures/table3.png" class="w-100 zoom-img">
                    </div>
                </div>
            </div>

            <div class="row">
                <div class="col-md-6">
                    <div class="result-card">
                        <img src="figures/table4.png" class="w-100 zoom-img">
                    </div>
                </div>
                <div class="col-md-6">
                    <div class="result-card">
                        <img src="figures/table5.png" class="w-100 zoom-img">
                    </div>
                </div>
            </div>

            <div class="row">
                <div class="col-md-5">
                    <div class="result-card">
                        <img src="figures/table6.png" class="w-100 zoom-img">
                    </div>
                </div>
                <div class="col-md-7">
                    <div class="result-card">
                        <img src="figures/table7.png" class="w-100 zoom-img">
                    </div>
                </div>
            </div>

            <!-- More Results Collapse -->
            <div class="text-center mt-4">
                <button class="button is-rounded" type="button" data-bs-toggle="collapse" data-bs-target="#moreResults">
                    <span>Show More Experiments</span>
                    <span class="icon is-small"><i class="fas fa-angle-down"></i></span>
                </button>
            </div>

            <div class="collapse mt-4" id="moreResults">
                <div class="row">
                    <div class="col-md-6">
                        <div class="result-card">
                            <img src="figures/table8.png" class="w-100 zoom-img">
                        </div>
                    </div>
                    <div class="col-md-6">
                        <div class="result-card">
                            <img src="figures/table9.png" class="w-100 zoom-img">
                        </div>
                    </div>
                    <div class="col-md-6">
                        <div class="result-card">
                            <img src="figures/table10.png" class="w-100 zoom-img">
                        </div>
                    </div>
                    <div class="col-md-6">
                        <div class="result-card">
                            <img src="figures/table11.png" class="w-100 zoom-img">
                        </div>
                    </div>
                </div>
            </div>

        </div>
    </section>

    <!-- Visualizations (Full Width) -->
    <section class="viz-section">
        <!-- ‰ΩøÁî® container-fluid ÂÖÅËÆ∏ÂÖ®ÂÆΩÊòæÁ§∫ -->
        <div class="container-fluid" style="padding: 0;">
            <h2 class="section-title">Visualizations</h2>

            <div id="vizCarousel" class="carousel slide" data-bs-ride="carousel">
                <div class="carousel-indicators">
                    <button type="button" data-bs-target="#vizCarousel" data-bs-slide-to="0" class="active"></button>
                    <button type="button" data-bs-target="#vizCarousel" data-bs-slide-to="1"></button>
                    <button type="button" data-bs-target="#vizCarousel" data-bs-slide-to="2"></button>
                    <button type="button" data-bs-target="#vizCarousel" data-bs-slide-to="3"></button>
                    <button type="button" data-bs-target="#vizCarousel" data-bs-slide-to="4"></button>
                    <button type="button" data-bs-target="#vizCarousel" data-bs-slide-to="5"></button>
                </div>

                <div class="carousel-inner">
                    <!-- Item 1 -->
                    <div class="carousel-item active">
                        <div class="carousel-item-container">
                            <img src="figures/fig5.png" alt="SFT vs RL">
                        </div>
                        <div class="carousel-caption-box">
                            <strong>SFT vs. RL.</strong> Examples are sampled from the GRES benchmark. RL finds more
                            target objects, localizes relative positions better, and produces cleaner masks than SFT
                            across diverse scenes.
                        </div>
                    </div>

                    <!-- Item 2 -->
                    <div class="carousel-item">
                        <div class="carousel-item-container">
                            <img src="figures/fig6.png" alt="Reconstruction">
                        </div>
                        <div class="carousel-caption-box">
                            <strong>Region mask reconstruction examples.</strong> For each region, the ground-truth mask
                            is tokenized into two discrete codes, and SAMTok reconstructs the mask solely from the
                            original image and the quantized mask tokens. SAMTok preserves fine structures for small,
                            thin, or irregular objects even under challenging lighting or clutter. Since SAMTok is fully
                            decoupled from the MLLM, its reconstruction quality remains stable regardless of downstream
                            model training‚Äîunlike joint-training mask tokenizers that tend to collapse to elliptical or
                            blurred masks.
                        </div>
                    </div>

                    <!-- Item 3 -->
                    <div class="carousel-item">
                        <div class="carousel-item-container">
                            <img src="figures/fig7.png" alt="PSG">
                        </div>
                        <div class="carousel-caption-box">
                            <strong>Panoptic scene graph generation(PSG) examples.</strong> The model predicts
                            subject‚Äìrelation‚Äìobject triplets where both subject and object categories are paired with
                            their corresponding segmentation masks, represented through mask tokens. SAMTok‚Äôs interface
                            allows the MLLM to generate consistent object masks and relational descriptions
                            simultaneously, demonstrating strong alignment between textual predicates and pixel-grounded
                            regions.
                        </div>
                    </div>

                    <!-- Item 4 -->
                    <div class="carousel-item">
                        <div class="carousel-item-container">
                            <img src="figures/fig8.png" alt="GRES">
                        </div>
                        <div class="carousel-caption-box">
                            <strong>GRES examples.</strong> Given a natural-language referring expression, the MLLM
                            outputs two mask tokens that decode into the final segmentation mask. SAMTok enables precise
                            grounding for expressions involving fine attributes, part-level targets, or contextual
                            reasoning. The examples show robustness to ambiguous descriptions, occlusion, and
                            multi-object scenes.
                        </div>
                    </div>

                    <!-- Item 5 -->
                    <div class="carousel-item">
                        <div class="carousel-item-container">
                            <img src="figures/fig9.png" alt="Region Caption">
                        </div>
                        <div class="carousel-caption-box">
                            <strong>Region Caption examples.</strong> Each visualization shows a region mask input
                            (tokenized as two mask tokens) and the model‚Äôs generated description. SAMTok provides
                            unambiguous spatial grounding, enabling the MLLM to generate accurate and context-aware
                            region descriptions about attributes, roles, and interactions.
                        </div>
                    </div>

                    <!-- Item 6 -->
                    <div class="carousel-item">
                        <div class="carousel-item-container">
                            <img src="figures/fig10.png" alt="GCG">
                        </div>
                        <div class="carousel-caption-box">
                            <strong>GCG examples.</strong> The model simultaneously describes the scene and produces
                            region masks for phrases mentioned in the caption. For each highlighted phrase, SAMTok
                            decodes the predicted mask tokens into segmentation masks. SAMTok‚Äôs compact representation
                            (two tokens per mask) enables efficient, aligned text‚Äìmask generation with consistent
                            grounding across multiple phrases within long captions.
                        </div>
                    </div>

                </div>

                <button class="carousel-control-prev" type="button" data-bs-target="#vizCarousel" data-bs-slide="prev">
                    <span class="carousel-control-prev-icon" aria-hidden="true"></span>
                    <span class="visually-hidden">Previous</span>
                </button>
                <button class="carousel-control-next" type="button" data-bs-target="#vizCarousel" data-bs-slide="next">
                    <span class="carousel-control-next-icon" aria-hidden="true"></span>
                    <span class="visually-hidden">Next</span>
                </button>
            </div>
        </div>
    </section>

    <!-- Citation -->
    <section class="section">
        <div class="container is-max-desktop">
            <h2 class="title is-4 has-text-centered">Citation</h2>
            <div class="box has-background-light" style="border: 1px solid #ccc;">
                <pre style="background: transparent;"><code>@article{zhou2024samtok,
  title={SAMTok: Representing Any Mask with Two Words},
  author={Zhou, Yikang and Zhang, Tao and Gong, Dengxian and others},
  journal={arXiv preprint arXiv:2408.03326},
  year={2024}
}</code></pre>
            </div>
        </div>
    </section>

    <footer class="footer">
        <div class="content has-text-centered">
            <p>
                This website is licensed under a <a rel="license"
                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0
                    International License</a>.
            </p>
        </div>
    </footer>

    <script>
        // ÂàùÂßãÂåñ Medium Zoom
        mediumZoom('.zoom-img', {
            margin: 24,
            background: '#fff',
            scrollOffset: 0
        });
    </script>
</body>

</html>